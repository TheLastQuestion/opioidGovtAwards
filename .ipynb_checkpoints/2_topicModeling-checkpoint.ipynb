{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up our libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/bryant/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords') #download the latest stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bryant/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (13,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1040239, 26)\n"
     ]
    }
   ],
   "source": [
    "# import our data\n",
    "\n",
    "df = pd.read_csv('mergedProjectsAbstracts.csv',encoding='utf-8-sig')\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. Project Terms Contain 'Opioid'\n",
    "\n",
    "The fedreporter data have a project_terms field. A subset of projects\n",
    "contain 'opioid' in that field. Let's make a flag for that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "\n",
    "df['projectTermsFlag'] = pd.to_numeric(np.where(\n",
    "    df['PROJECT_TERMS'].str.contains(\"opioid\", case=False, na=False), 1, ''))\n",
    "\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(time.time() - st)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% flagged: 0.8569184581620185\n"
     ]
    }
   ],
   "source": [
    "print('% flagged: ' + str(100*df['projectTermsFlag'].value_counts()[1]/len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. 'Wiki Approach'\n",
    "\n",
    "If we read through the [opioid wikipedia page](https://en.wikipedia.org/wiki/Opioid) we can extract words to highlight in project abstracts that might indicate it is a project related to opioids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# terms/n-grams gleaned from wikipedia\n",
    "opioid_terms = ['opioid','opiate','morphine','heroin',\n",
    "                'percocet','vicoprofen','dextromethorphan','loperamide',\n",
    "                'naloxegol','hydrocodone','oxycodone','fentanyl',\n",
    "                'naloxone','analgesics','carfentanil','benzodiazepines',\n",
    "                'narcotic','opium','cocaine','codeine',\n",
    "                'pain relief','cancer pain','anesthesia','chronic pain',\n",
    "                'nerve pain','fibromyalgia','overdose','addiction',\n",
    "                'withdrawal','dependence','recreational use','euphoria',\n",
    "                'tolerance','controlled substance','over-prescription',\n",
    "                'peripheral nervous system','psychoactive','agonist',\n",
    "                'antagonist','blood-brain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:06:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bryant/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# clean up the abstracts for text matching\n",
    "st = time.time()\n",
    "\n",
    "# a regex pattern to help eliminate punctuation\n",
    "nonchars = re.compile( r'\\W+|\\d+' )\n",
    "\n",
    "# function to elim punctuation and set to lower case\n",
    "def clean(text):\n",
    "    return re.sub(nonchars, \" \", text).lower()\n",
    "\n",
    "# cut the end coding that interferes with cleaning function\n",
    "# df = df[0:-1]\n",
    "\n",
    "# drop nulls, as they don't help our analysis\n",
    "df_denull = df[df.ABSTRACT.notnull()]\n",
    "\n",
    "# may have to drop weird end coding that interferes with cleaning function\n",
    "# df_denull = df_denull[0:-1]\n",
    "\n",
    "df_denull['cleanText'] = df_denull['ABSTRACT'].apply(clean)\n",
    "\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(time.time() - st)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bryant/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/bryant/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:46:06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bryant/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "\n",
    "# Count the appearances of our defined terms in each abstract\n",
    "def countTerm(text):\n",
    "    return len(re.findall(term,text))\n",
    "\n",
    "for term in opioid_terms:\n",
    "    df_denull[term] = df_denull['cleanText'].apply(countTerm)\n",
    "    \n",
    "# sum of all term frequencies by abstract\n",
    "df_denull['sumTermCounts'] = df_denull[opioid_terms].sum(axis=1)\n",
    "\n",
    "# set term threshold\n",
    "wikiThreshold = 2;\n",
    "\n",
    "def wikiFlag(row):\n",
    "    if row['sumTermCounts'] > wikiThreshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "df_denull['wikiTermsFlag'] = df_denull.apply(wikiFlag, axis=1)\n",
    "\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(time.time() - st)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_denull['wikiTermsFlag'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3. Text analysis (Topic modeling)\n",
    "\n",
    "LDA (Latent Dirichlet Allocation) is a model used for discovering abstract topics from a collection of documents. These 'latent' topics can be discovered based on observed data -- words in the documents, in this case.\n",
    "\n",
    "To surface these topics, we create a matrix where each document is a row and each column is a word in the corpus vocabulary. The corpus vocabulary is the universe of words present in any one or more documents in the corpus (minus chosen 'stopwords' that we consider to provide little information).\n",
    "\n",
    "Each cell of the matrix would be a count of that word in that document. A variant increases the level of sophistication by using a normalized version of these counts known as TF-IDF. TF stands for term-frequency and TF-IDF is term-frequency times inverse document-frequency. In other words, we are not only looking for how often a word appears in a given document, but also whether this particular word is distinct across all the collections of documents (corpus). For example, intuitively we understand that words like \"often\" or \"use\" are more frequently encountered, but they are less informative (more semantically-vacuous) if we want to discern a particular topic of a document, as they might be frequently encounter across all text documents in a corpus. On the other hand, words which we will see less frequently across a collection of document might indicate that those words are specific to a particular document, and, therefore, constitute a basis for a topic.\n",
    "\n",
    "We provide the model with this matrix and how many topics we want it to use. Think of it like a k-means clustering analog. The model will then iterate a specified number of times considering two distributions; 1) which words in the vocabulary are more or less probable to belong in a given topic and 2) which topic is more or less probable for a given document.\n",
    "\n",
    "The main assumptions, if this all went over your head:\n",
    "* each document consists of a mixture of topics, and\n",
    "* each topic consists of a collection of words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1040239, 2)\n"
     ]
    }
   ],
   "source": [
    "# prepare a df of just abstracts\n",
    "abstracts = df[['PROJECT_ID', 'ABSTRACT']]\n",
    "print(abstracts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1032895, 2)\n"
     ]
    }
   ],
   "source": [
    "# drop nulls\n",
    "trunc_abstracts = abstracts.dropna()\n",
    "print(trunc_abstracts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up our corpus (limit number of rows while perfecting code)\n",
    "df_modeling = trunc_abstracts[:1000]\n",
    "# df_modeling = trunc_abstracts\n",
    "\n",
    "# Get only the text of abstracts\n",
    "corpus = df_modeling['ABSTRACT'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop words and stemming them\n",
    "stemmer = nltk.SnowballStemmer('english')\n",
    "eng_stopwords = stopwords.words('english')\n",
    "add_stopwords = ['understand','method']\n",
    "comb_stopwords = eng_stopwords + add_stopwords\n",
    "stemmed_stopwords = []\n",
    "\n",
    "for w in comb_stopwords:\n",
    "    stemmed_stopwords.append(stemmer.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:00:03\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "'''\n",
    "Before we can apply LDA, we need to create a vocabulary with all the words in our data\n",
    "We specify to only include those words that appear in less than 10% of the document \n",
    "and appear in at least 0.5% of documents. \n",
    "docs: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n",
    "The exercise of running the vectorizer on each year independently, then only\n",
    "keeping ngrams that all 10 years of abstracts possess is all geared towards breaking up\n",
    "the computation into manageable chunks that won't crash the kernel.\n",
    "'''\n",
    "\n",
    "# prepare our vectorizer\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "# our stemming function\n",
    "def stemmed_words(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "stem_vectorizer = CountVectorizer(analyzer=stemmed_words,\n",
    "                                  max_df=0.10,\n",
    "                                  min_df=0.005,\n",
    "#                                   max_features = 1500, # useful for limiting coderun duration\n",
    "                                  ngram_range = (0,2),\n",
    "                                  stop_words=stemmed_stopwords)\n",
    "\n",
    "doc_term_matrix = stem_vectorizer.fit_transform(corpus)\n",
    "doc_term_features = stem_vectorizer.get_feature_names()\n",
    "\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(time.time() - start_time)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUsing below code, we can print out the many, many words excluded due to:\\n- occurred in too many documents (max_df)\\n- occurred in too few documents (min_df)\\n- were cut off by feature selection (max_features)\\n'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Using below code, we can print out the many, many words excluded due to:\n",
    "- occurred in too many documents (max_df)\n",
    "- occurred in too few documents (min_df)\n",
    "- were cut off by feature selection (max_features)\n",
    "'''\n",
    "\n",
    "# print(count_vect.stop_words_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:00:03\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Use LDA to create topics.\n",
    "\n",
    "LDA = LatentDirichletAllocation(n_components=10, random_state=1)  \n",
    "LDA.fit(doc_term_matrix)\n",
    "\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(time.time() - start_time)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize list for topics\n",
    "topicList = []\n",
    "\n",
    "# fill out topics list as top 20 words in each topic\n",
    "for i,topic in enumerate(LDA.components_):\n",
    "    ithTopic = [doc_term_features[i] for i in topic.argsort()[-20:]]\n",
    "    topicList.append(ithTopic)\n",
    "    \n",
    "topicListDf = pd.DataFrame(topicList)\n",
    "# topicListDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of topic_values:  (1000, 10)\n",
      "00:00:39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bryant/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/bryant/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "'''\n",
    "Assign the probability of all the topics to each document, then\n",
    "add a column to the original data frame that will store the highest-scoring\n",
    "topic for that abstract.\n",
    "'''\n",
    "\n",
    "# matrix where each row is an abstract, each column a topic. Each cell is value of that topic for that abstract.\n",
    "topic_values = LDA.transform(doc_term_matrix)  \n",
    "\n",
    "'''\n",
    "take the column number associated with the highest value in a given row, store in our analytical dataframe\n",
    "'''\n",
    "df_modeling['primeTopicId'] = topic_values.argmax(axis=1)\n",
    "\n",
    "'''\n",
    "store the valence of that prime topic for that abstract as well\n",
    "'''\n",
    "df_modeling['primeTopicValence'] = topic_values.max(axis=1)\n",
    "\n",
    "print(\"Shape of topic_values: \",(topic_values.shape))\n",
    "\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(time.time() - start_time)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which topics are most common among projects tagged explicitly?\n",
    "pd.DataFrame(df_modeling[df_modeling.tagCompare == 'both'].primeTopicId.value_counts())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:00:03\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Convert a collection of raw documents to a matrix of TF-IDF features\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf = vectorizer.fit_transform(abstracts_list)\n",
    "\n",
    "# Get feature names\n",
    "vectorizer_feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "# Run the model with 10 topics\n",
    "nmf = NMF(n_components=5, random_state=1).fit(tfidf)\n",
    "\n",
    "nmf_W = nmf.transform(tfidf) # get topics to documents matrix\n",
    "nmf_H = nmf.components_ # get word to topics matrix\n",
    "\n",
    "nmf_W[0]\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "----------------------------\n",
      "indicators research environmental project species water land ecosystem ecological objective\n",
      "----------------------------\n",
      "Topic 1:\n",
      "----------------------------\n",
      "toxic air metal emissions trace disseminate releases element worldwide implementation\n",
      "----------------------------\n",
      "Topic 2:\n",
      "----------------------------\n",
      "pm particles effects exposure health particulate studies air matter ambient\n",
      "----------------------------\n",
      "Topic 3:\n",
      "----------------------------\n",
      "process treatment soil water waste project design technology contaminated organic\n",
      "----------------------------\n",
      "Topic 4:\n",
      "----------------------------\n",
      "ozone lung exposure cells ntp air standard ppm effects function\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "# View the list of topics (10 top words per topic)\n",
    "\n",
    "for topic_idx, topic in enumerate(nmf_H):\n",
    "    print(\"Topic %d:\" % (topic_idx))\n",
    "    print('----------------------------')\n",
    "    print(\" \".join([vectorizer_feature_names[i]\n",
    "                for i in topic.argsort()[:-10 - 1:-1]]))\n",
    "    print('----------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Topic 0:\n",
      "--------------------\n",
      "protein dna gene proteins genes genetic expression genome rna molecular\n",
      "--------------------\n",
      "DESCRIPTION (provided by applicant): The regulation of gene expression is vital for healthy development and physiology, and many diseases are caused by or associated with changes in gene expression. In the past decade, a tremendous amount of information has been gathered regarding transcriptional control by transcription factors that bind directly to regulatory DNA sequences in or around their target genes. In addition, microRNAs that control gene expression post-transcriptionally have been studied extensively. However, functional and biochemical information about the vast majority of RNA binding proteins has been lacking despite clear evidence of their importance in development and disease. A major factor contributing to our limited understanding of post- transcriptional control by RNA binding proteins is a shortage of appropriate technologies that start with an important mRNA, for instance corresponding to a disease gene of interest, and identify the RNA binding proteins with which this mRNA interacts.  In the proposed project, we will develop a novel, high-throughput method for the detection and identification of RNA-protein interactions. We have provisionally named this technology  RNA-associated protein interaction detection  (RAPID). RAPID is based on translation and mimics endogenous RNA binding protein activity. We will first develop and apply RAPID to RNA-protein interactions in the nematode Caenorhabditis elegans because it provides a highly suitable model for further in vivo studies, and because we have clone resources such as the ORFeome available, which contains numerous full-length RNA binding protein-encoding clones.  Successful completion of this project will provide the research community with a novel and broadly applicable method to detect RNA-protein interactions in an unbiased and high-throughput manner. We envision applying RAPID to the genome-scale detection of such interactions to further our understanding of complex gene regulatory networks. The methodology and RNA binding protein resource that we will develop for C. elegans will provide an important blueprint for the creation of similar resources in other model organisms and humans.    PUBLIC HEALTH RELEVANCE: The regulation of gene expression is vital for healthy development and homeostasis and many diseases are caused by or associated with changes in gene expression. In recent years, tremendous progress has been made in the study of individual RNA binding proteins and how they affect gene expression. However, the genome encodes hundreds of such proteins, and methods that enable the characterization of many at one time are lacking. The proposed project is to develop a novel technology that will be broadly applicable for the functional and large-scale characterization of RNA binding proteins, and will impact both the fields of systems biology of gene expression and researchers that study one or a few disease-relevant human genes.\n",
      "--------------------\n",
      "Topic 1:\n",
      "--------------------\n",
      "training program research trainees faculty students clinical university career biology\n",
      "--------------------\n",
      "DESCRIPTION (provided by applicant): We propose a training program designed to attract and train physicians in a two year fellowship devoted to research on the pathophysiology of the response to injury. The goals of this training program are to nurture talented young individuals in the areas of basic-research and clinical investigation, to teach them to design and perform successful research projects, and to give them a solid background in the ethics and methods of scientific research. The objective of this fellowship is to increase the focus of research on injury within the University of North Carolina and to train individuals to become independent investigators and academic faculty with an interest in the area of trauma. Trainees will be selected from a broad group of candidates. Special efforts will be made to identify minority applicants who will increase the diversity of our trainees in this and other institutions. The training program is two years of full-time effort working with one or more of a large group of talented faculty mentors. Research projects are concentrated in the areas of organ failure after injury, immunology and host resistance. Weekly seminars with the trainees allow them to present their material to the research community. Additionally, trainees are required to present their research at Surgery Grand Rounds, and submit abstracts to national meetings. Two intensive week-long courses, Responsible Conduct of Research and Methods in Clinical Research, are provided for trainees in the first month of the program. Trainees have the opportunity to attend graduate level courses from the broad range available at the UNC-CH and surrounding area universities to enhance their research experience. The Training Advisory Committee will assist the Program Director in recruitment and selection of trainees, approval of trainee's research and didactic plans, assignment of trainee to appropriate Research Training Faculty, and monitoring of program activities. The Program Evaluation Committee will provide overall evaluation of the training program and provide feedback to the Training Committee.  All of the Research Training Faculty in the program is established investigators with current NIH funding or other extramural funding, and is experienced mentors of physician-scientists. The faculty has diverse interests, allowing multiple candidates to find appropriate mentors within the training program. There is strong institutional history of multidisciplinary collaboration. A group of Clinician-Scientist mentors will provide guidance to trainees through discussion of the clinical dimensions of the research.\n",
      "--------------------\n",
      "Topic 2:\n",
      "--------------------\n",
      "subproject nih institution center ncrr subprojects listed isfor andinvestigator crisp\n",
      "--------------------\n",
      "This subproject is one of many research subprojects utilizing theresources provided by a Center grant funded by NIH/NCRR. The subproject andinvestigator (PI) may have received primary funding from another NIH source,and thus could be represented in other CRISP entries. The institution listed isfor the Center, which is not necessarily the institution for the investigator.N/A\n",
      "--------------------\n",
      "Topic 3:\n",
      "--------------------\n",
      "health care risk intervention study children patients outcomes treatment clinical\n",
      "--------------------\n",
      "DESCRIPTION (provided by applicant): Cardiovascular disease continues to be the leading cause of death and disability in the US. While lifestyle and medication use can substantially reduce CVD risk, both are underused forms of treatment. Accordingly, we propose to combine previously tested and effective lifestyle and medication interventions to reduce CVD risk and test this intervention in a diverse group of patients cared for at family practices in North Carolina. Our plan is to identify a potential intervention that is practical for use in common office settings supported by community resources so that it may reach a large segment of the population and thus have major public health impact. In recognition of increasing access to the internet and differing costs and in-puts related to web-based vs. counselor-based interventions, we will compare the effectiveness and feasibility of the combined intervention in two formats, web-based and counselor-based. Using a comparative effectiveness research framework, we plan to compare these intervention formats for their impact on estimated CVD risk reduction and other important outcomes to key clinical and public health stakeholders (patients, payers, and decision makers); in particular, feasibility, acceptability, and cost-effectiveness outcomes. To do so, we will conduct this study at 5 family practices, enrolling 120 patients per practice. We will randomize participants within site to one of the 2 treatment conditions, both including a baseline assessment and a theory informed intervention with a 4 month intensive phase (4 sessions) and an 8 month maintenance phase (3 contacts). Outcomes will be assessed at 4 and 12 months, with the primary outcome a reduction in the estimated 10 year risk of coronary heart disease as determined by the Framingham equation. Changes in dietary intake, physical activity, blood pressure, blood lipids, and medication use, in addition to feasibility, acceptability and cost, are important secondary outcomes. To optimize dissemination of study findings to decision makers and the interventions to practitioners, we will 1) elicit input from stakeholders at the outset to guide our development of the intervention and 2) use an existing web-based mechanism, (Center of Excellence for Training and Research Translation) for intervention training, translation, and dissemination.  Project Summary: Statement of problem: Cardiovascular disease continues to be the leading cause of morbidity and mortality in the US. While lifestyle and appropriate use of medication can substantially reduce this risk, both are underused forms of treatment.  Purpose of proposed research: To combine previously tested and effective lifestyle and medication interventions to reduce CVD risk and test this intervention in a diverse group of patients cared for at family practices in North Carolina. Our plan is to identify a potent intervention that is practical for use in common office settings supported by community resources so that it may reach a large segment of the population and thus have major public health impact.  Which IOM public health CER priority area are being addressed by this research? This application addresses 4 of the 14 IOM priority topics, includes 2 topics in the first quartile (listed first): 1. Compare the effectiveness of various strategies to prevent obesity, hypertension, diabetes, and heart disease in at-risk populations such as the urban poor and American Indians 2. Compare the effectiveness of interventions to reduce health disparities in cardiovascular disease, diabetes, cancer, musculoskeletal diseases, and birth outcomes 3. Compare the effectiveness of alternative redesign strategies-using decision support capabilities, electronic health records, and personal health records-for increasing health professionals' compliance with evidence - based guidelines and patients' adherence to guideline-based regimens for chronic disease care 4. Compare the effectiveness of different quality improvement strategies in disease prevention, acute care, chronic disease care, and rehabilitation services for diverse populations of children and adults.\n",
      "--------------------\n",
      "Topic 4:\n",
      "--------------------\n",
      "cancer breast tumor prostate clinical cancers tumors nci patients trials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "The SEER Program was initiated in 1972 in response to requirements of the National Cancer Program for assessing the magnitude of the cancer burden in the United States, and for identifying factors related to cancer risk and/or patient survival. The SEER Program has among its objectives: 1. \tTo assemble and report, on a periodic basis, estimates of cancer incidence, especially among the following key cancer sites: breast cancer, lung cancer, colorectal cancer, prostate cancer, pancreatic cancer, and urinary bladder cancer.2. \tTo monitor annual cancer incidence trends to identify unusual changes in specific forms of cancer occurring in population subgroups defined by geographic, demographic, and social characteristics. 3. \tTo provide continuing information on changes over time in extent of disease at diagnosis, trends in therapy, and changes in cancer patient survival. 4. \tTo identify the occurrence of possible iatrogenic cancers, i.e., cancers that are caused by cancer therapy. 5. \tTo serve as a research resource to the National Cancer Institute, and conduct studies dealing with current cancer control issues as well as problems related to the operation of the SEER Program.\n",
      "--------------------\n",
      "Topic 5:\n",
      "--------------------\n",
      "hiv infection infected aids viral virus vaccine drug transmission prevention\n",
      "--------------------\n",
      "DESCRIPTION (provided by applicant): The overarching goals of our renewal proposal are to develop an integrated program to further our ability to provide evidenced-based, potent antiretroviral therapy (ART) to patients with HIV-2 infection. Compared to HIV-1, HIV-2 infection is characterized by a longer asymptomatic stage, lower plasma viral loads, slower decline in CD4 count, decreased mortality rate due to AIDS, lower rates of mother to child transmission, and lower rates genital shedding and sexual transmission. In West Africa, where both HIV-1 and HIV-2 co- circulate, between 1-2 million individuals are infected with HIV-2 and a significant proportion are co-infected with both HIV-1 and HIV-2. Despite the relatively attenuated disease course of HIV-2, a significant minority of untreated individuals will progress to clinical AIDS or death without ART and as will the majority of those dually infected with HIV-1 and HIV-2. Through local and global initiatives, antiretroviral therapy is becoming increasingly available in resource-limited West Africa. Because HIV-2 is intrinsically resistant to non-nucleoside reverse transcriptase inhibitors and may have partial resistance to some protease inhibitors (PI), treating HIV-2 and HIV-1/HIV-2 dual infection presents distinct challenges. This is especially problematic in resource-limited settings where there is limited choice and availability of 1st- line NRTI-PI based regimens as well as subsequent 2nd- line and salvage regimens in those individuals with clinical progression, immuno-virologic failure or antiretroviral (ARV) toxicities. During the initial period of our grant proposal we (and others) have made substantial progress in furthering our understanding ART for HIV-2 in ARV-naove adults as well as HIV-2 ARV-resistance. However, to date, we remain largely ignorant about the long-term outcomes of ART in HIV-2 infected people, we are in urgent need for assessment of new classes antiretrovirals for HIV-2 and we lack even rudimentary studies on ARV-regimens to treat HIV-1/HIV-2 dual infection, or whether ARV treatment outcomes using NRTI-PI based regimens are different than HIV-2 single infection. Our Renewal proposal has the following specific aims: AIM 1: Long-term outcomes of ART for HIV-2 infection in Senegal: Determine long- term HIV/AIDS associated outcomes and ARV-associated complications in HIV-2 infected individuals treated with ART for >2 years. Assessment of the frequency, causes and outcomes of switching to 2nd line and salvage ARV regimens for HIV-2 infection. AIM 2: To determine the potential utility and susceptibility of HIV-2 to new ARV classes: the integrase inhibitors and the CCR5 co-receptor entry inhibitors. AIM 3: To compare the clinical, virologic and immunologic outcomes associated with ART using NRTI+PI based regimens in a longitudinal prospective cohort of 50 HIV-1/HIV-2 dually infected ARV-naove subjects and a longitudinal prospective cohort of 50 HIV-2 ARV-naove singly infected subjects. Our Renewal proposal will build on a strong ongoing collaboration between the University of Washington and the Universite Cheikh Anta Diop de Dakar, Senegal to further our understanding and provide evidence-based ART and care for HIV-2 infected people.  PUBLIC HEALTH RELEVANCE: In West Africa, two distinct AIDS viruses (HIV-1 and HIV-2) are found, and some people become infected by both types. Because HIV-1 and HIV-2 infection have different natural histories (with HIV-2 being less aggressive) and different antiretroviral drug susceptibilities (with HIV-2 being more drug resistant), treatment for HIV-2 and dual HIV-1/HIV-2 infection is clinically challenging. Understanding how to better treat HIV-2 and dual HIV-1/HIV-2 infection is an import public health priority in West Africa.\n",
      "--------------------\n",
      "Topic 6:\n",
      "--------------------\n",
      "core administrative projects center investigators research support data services cores\n",
      "--------------------\n",
      "The Data Management/Statistical Core is a key component of the Center. The Core will serve as a support mechanism to the Center's overall research program. The overall objective of the Core is to facilitate the ability of the Center's investigators to conduct research that is of the highest standards and to disseminate the research outcomes to the academic and service communities and industry. The Core will provide statistical and analytical support to the research programs at all of the sites. The Core will also provide technical support for the research projects. In addition, the Core will serve as the depository for the cross-site core battery of measures. The Core will build on the structures developed in CREATE I for data collection, storage, transfer, and management, and quality control for the core battery. The methods developed in CREATE I will be further enhanced during the proposed CREATE II project to ensure that they reflect recent strategies in data management and that they meet the requirements of the Center's proposed research program. The Core will also assume primary responsibility for analyzing the core battery data and provide statistical and analytical support for the planned cross-site longitudinal study (see Management Core) and all subsequent cross-site projects. In addition, the Core will provide consultation to the Center's investigators on research methods and statistical analyses for all of the proposed research projects, the pilot research studies, and any  spin-off  research projects. To ensure adequate communication with Center investigators the Co-Directors of the Core will be part of the Executive Working Group of the Center (see Management Core) and participate in the monthly conference calls and Center meetings. The Co-Directors for the Core will also participate in the preparation of project reports and manuscripts and dissemination of project outcomes. Finally, the Core will help to ensure that all projects are compliant with IRB andHIPAA regulations. The Core has been structured to balance data management and analytical responsibilities. The team of investigators that has been assembled for the Core has extensive experience in advanced statistical methods, research design, programming, and simulation. The ultimate goal of the Core is to maximize the integrity and quality of the Center's data and to ensure that the outcomes of the Center are of the highest standards.\n",
      "--------------------\n",
      "Topic 7:\n",
      "--------------------\n",
      "students project data research science systems materials engineering new methods\n",
      "--------------------\n",
      "The advancement of high-throughput high-content data acquisition techniques has pushed modern scientific research from traditional reductionism to constructionism for studying complex systems with a strong data-driven focus. However, there are still significant issues in big-data analytics, especially, regarding the reproducibility of data-driven research findings. To enable analytic methods from traditional reductionist scientific research to constructionist research with the help of rich data, an integrative Bayesian framework is proposed for systems prediction and intervention in high-dimensional network-based systems, which will provide ways to translate the unprecedented amount of heterogeneous data into reproducible scientific knowledge in a cumulative manner with novel concepts of objective-based uncertainty quantification and optimal experiment design based on that. The proposed knowledge-driven analytics has strong potential of transforming available diverse large-scale data for reproducible knowledge to drive life and materials science research. If successful, it can eventually lead to computational tools for more efficient experiment design to maximize the use of existing big data and speed up the process for effective disease therapeutics and new materials discovery. The interdisciplinary nature of this proposal promises to foster cross-fertilization of ideas between engineering, life science, and materials science through research and education. The broader impact of this proposal involves the integration of the proposed research with an educational plan: (1) to strengthen interactions with the collaborators in life and materials sciences. In addition to making all the tools and research outcomes from this project publicly available, the developed algorithms and tools, including necessary technical help, will be distributed to the collaborators for more effective collaboration; (2) to develop new courses interfacing engineering, mathematics, life and materials sciences and incorporate them into the engineering curriculum for education and research training of students at all levels, which will help the new generation of researchers to establish a broad and solid foundation for interdisciplinary research and prepare them with required skills to address real-world challenges. The courses will be available across campus to attract female and minority students who are interested in research in science and engineering; (3) to involve both undergraduate and graduate students in the research in this interdisciplinary field with the efforts to increasing the participation of underrepresented groups in science and engineering through the collaborations with the REU programs and other scholarship programs developed to increase diversity at Texas A&M University (TAMU). The scientific focus of this proposal is solving mathematical and computational problems that exist in high-dimensional network-based systems prediction and intervention with uncertain models. The following open problems will be addressed: (1) to develop a network-based Bayesian framework and methods for systematic analysis of heterogeneous data sets; (2) to define novel objective-based uncertainty quantification for assessing model uncertainty and data significance to enable cumulative analytics to improve systems understanding and optimize future experiment design; (3) to derive optimal Bayesian experiment design based on uncertainty quantification for different operational objectives, which can lead to the maximal use of existing data and effective future experiment design and systems intervention; and (4) to apply the developed methodologies for understanding and treating specific diseases, for example, cancer and type 1 diabetes; as well as designing experiments for new materials discovery in an efficient way, in collaboration with the collaborators in life and materials sciences, which will translate the knowledge to practical applications. This project will lay out the foundation for translating existing data into systems understanding of life, disease, and man-made systems to gain deeper insights and direct them to desirable systems behavior to benefit human society.\n",
      "--------------------\n",
      "Topic 8:\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cells cell immune stem tumor signaling mice il responses aim\n",
      "--------------------\n",
      "White blood cells called T lymphocytes play critical roles in immune defense against viruses, bacteria, fungi, protozoa, and cancer cells. In the unactivated state, these cells circulate in the blood and accumulate in lymphoid tissues such as lymph nodes and spleen. Upon encounter with foreign materials (antigens) on the membranes of specialized antigen presenting cells (dendritic cells), these resting T-cells become activated, undergo numerous cell divisions, and differentiate into effector cells. The effector cells leave the lymphoid tissues and blood, entering sites of infection to combat pathogens. They can also invade normal tissues where their activity can cause autoimmune pathology. After elimination of an infecting organism, most of the activated T-cells die, but some remain as memory cells, to provide a more rapid and vigorous response if the same pathogen is encountered in the future. Recent work has suggested that this general scheme applies to both CD4 and CD8 T-cells, but that there are also important differences in the signals that control the extent of proliferation and the survival of memory cells for these two T-cell lineages. Furthermore, there are also data suggesting that memory cells may be of more than one type, with some recirculating in lymphoid compartments and others patrolling peripheral tissues. The former may provide the major source of new cells upon re-infection, whereas the latter may mediate the earliest effector response to the infection. The proper balance of both types may be critical for effective T-cell mediated host defense. Other lymphocytes such as NK cells and regulatory T cells contribute to both the enhancement and suppression of these T cell responses through direct and indirect means. This project attempts to gain both a qualitative (especially tissue-specific 4 dimensional  space and time) and a quantitative understanding of the activation, differentiation, migration, cell-cell interaction, memory status, and reactivation properties of both CD4 and CD8 T-cells. Issues such as the route, amount, and frequency of antigen exposure, as well as the presence or absence of adjuvants that stimulate the innate immune system, are being studied for their effects on the generation and tissue distribution of effector and memory CD4 and CD8 T-cells. The movement of activated T-cells into non-lymphoid tissues is being analyzed using both conventional cellular immunological methods and newer imaging techniques that allow high resolution dynamic observation of how cells migrate, interact, and carry out their effector functions. Through this research, a better understanding of lymphocyte dynamics during an immune response to infection or after vaccination or during an autoimmune response will be established. These new insights can contribute to the more effective design of vaccines and to strategies for the amelioration of autoimmune processes.We have established a robust system for vaccination using the non-replicating pox vector MVA, to permit in situ analysis of immune cell behavior in response to a clinically used vaccine vector. Variants of the virus have been developed that encode both fluorescent proteins and model antigens that are recognized by TCR transgenic T cells expressing distinct fluorescent proteins. This allows for tracking of the sites of viral infection and of the location and dynamic behavior of antigen-specific T cells during immune responses in situ, using our advanced 2-photon intravital imaging methods. Preliminary studies have suggested unexpected locations for some of the cells initially infected by MVA within draining lymph nodes, potentially distinct cells involved in initial antigen presentation to CD4 T cells vs. CD8 T cells, the rapid loss of directly infected cells, a role for cross-presentation as well as direct presentation in the activation of CD8 T cells, and different locations of naive vs. memory CD8 T cells in the lymph node. In the case of the distinct sites of CD4 and CD8 T cell antigen engagement, we are now trying to understand how what appears to be dispersed initial antigen activation of these two cell types on different antigen-presenting cells can be reconciled with data from other laboratories and from the LBS that indicate a requirement for antigen co-presentation to the CD8 and CD4 T cells on the same dendritic cells for induction of robust immune memory. We have also utilized this model for examine the effect of regulatory T cells (Tregs) on the MVA-induced response and have obtained data showing a striking differential effect of these cells on CD8 T cells, especially with respect the balance of highly polarized effectors versus multifunctional/ memory T cells emerging after priming. We have dissected the mechanism of the suppression of effector generation by Tregs, revealing a key role for limitation in the late (post-activation) availability of the cytokine IL-2. In other experiments building on a combination of our highly multiplexed immunofluorescence imaging and our 2-photon intravital methods, we have accumulated data on the delivery of antigen from subcutaneous sites to the draining lymph node and the role of distinct subpopulations of macrophages and dendritic cells in acquiring the antigen in different regions of the lymph node. With respect to effector function, a combination of intravital imaging and flow cytometry studies in a model of delayed-type hypersensitivity have revealed that effector cells in an inflamed, not tolerogenic, site undergo a single round of activation to cytokine secretion status in concert with an arrest of migration, followed by a loss of cytokine production as the cells mobilize from the antigen presenting cell and resume rapid movement in the tissue that lasts as long as we can image (>10 hours). These data imply a mechanism of tuning of effector cells upon initial activation in the tissue that limits damaging cytokine production if the antigen load is not increasing, and also suggests that eventual elimination of a pathogen will depend on a constant influx of new effectors from secondary lymphoid tissue. Preliminary data suggest that a negative feedback loop involving regulatory surface proteins whose expression increases shortly after antigen stimulation of effector T cells in the tissue depresses signaling through the TCR and hence, desensitizes the T cells with respect to the available antigen level.We are continuing our studies of activated T cell help for humoral antibody responses from B cells, with a focus on the generation and behavior of follicular helper CD4 T cells (Tfh). New reporter systems are being developed to track these cells and to characterize their dynamic and functional interactions with B cells in the interfollicular region and especially within germinal centers. Progress has been made in the initial steps of constructing and validating a novel reporter of Bcl6 protein expression (rather than gene transcription).Finally, we have developed new data suggesting that the in vitro paradigm of autocrine cytokine-induced polarization of CD4+ T cells is an oversimplification of the in vivo reality.  In particular, both in vitro and in vivo, under suitable conditions, Th1 and Th2 effector T cells can be generated in the absence of the canonical cytokine (IFNgamma and IL-4, respectively), or the relevant STAT protein. A key determinant of the fate of the T cells is the strength of signaling through the T cell antigen receptor, and in vivo, preliminary data suggest that changes to dendritic cell morphology and capacity for cell-cell interactions plays an important role in determining the strength of signaling to T cells and their ultimate polarized fate.\n",
      "--------------------\n",
      "Topic 9:\n",
      "--------------------\n",
      "brain neurons cognitive neural imaging ad memory synaptic neuronal activity\n",
      "--------------------\n",
      "DESCRIPTION (provided by applicant): Parkinson's disease (PD) leads to cognitive deficits that can be more disturbing to patients than the motor symptoms, yet these symptoms are overlooked and untreated despite their high frequency in early disease stages and the high risk for future mild cognitive impairment or dementia. Most PD patients eventually develop dementia, which is up to five times more prevalent than in normal aging. With emerging applications of functional magnetic resonance imaging (fMRI), there is mounting evidence of abnormal brain functioning in PD even when performance is normal on clinical testing. Early structural changes in gray- and white-matter tissue also are associated with subtle changes in cognition in PD patients without dementia. Prediction of cognitive changes before clinical symptoms manifest is vital since optimal interventions will ultimately depend on early detection. The primary goal of this proposal is to identify early multimodal signatures of brain dysfunction in different networksimplicated in the development of cognitive impairment in PD. The neural bases of subtle cognitive changes in early stages of PD are not well understood. This has been hampered by a paucity of studies that probe for dysfunction in different brain networks implicated in the development of different types of cognitive impairment. Changes in some networks may be more prognostic of the risk for dementia than changes in others. Moreover, most studies focus on disease-related changes in the amount of brain activation, which is insensitive to communications among brain regions. Since brain regions interact to fulfill a cognitive function, it is essential to study their functional connectivity, which may be a more significant intermediat phenotype of early pathology. It is also critical to consider that the functionality of brain netwoks may depend partly on the structural integrity of grey- and white-matter tissue, yet this also has not been studied in PD. To this end, the proposed project will identify abnormal functional connectivity in different brain networks as measured from the blood oxygen level dependent (BOLD) signal during task-activated fMRI. We will then determine if abnormal functional connectivity in each brain network is related to a loss in white- matter tract integrity or gray-matter volume using diffusion tensor imaging (DTI) and structural MRI (sMRI). PD patients and healthy control subjects will undergo fMRI as they perform three cognitive tasks that probe for functioning in brain networks implicated in the development of cognitive impairment, namely tests of temporal integration, visuospatial working memory, and inhibitory control. Aim 1 will identify disease-related functional changes in the connectivity of brain circuits that govern each cognitive function. The main hypotheses are that functional connectivity in PD will be altered in brain circuits that govern temporal integration (cortico-basal ganglia thalamocortical system), visuospatial working memory (dorsolateral prefrontal cortex circuit, dorsal and ventral attention networks), and inhibitory control (ventral lateral orbitofrontal circuit). Aim 2 will then determin if abnormal functional connectivity of the different brain networks identified by fMRI is associated with a loss in white-matter fiber-tract integrity using DTI tractography. The main hypothesis is that abnormal functional connectivity in brain networks that govern processing in each cognitive domain will best correlate with abnormal tissue diffusivity in the same pathways. For Aim 3, sMRI analyses will be conducted to determine if abnormal functional connectivity of the different brain networks correlates with volume loss. The main hypothesis is that abnormal functional connectivity in brain networks that govern processing in each cognitive domain will correlate with frontostriatal and/or temporal atrophy. Our multimodal inquiry into identifying neuroimaging markers of cognitive changes in distinct brain networks, before clinically significant symptoms manifest, be the first of its kind in PD and will promote a new understanding of pathological mechanisms of cognitive dysfunction. Ultimately, outcomes from this research may inform the selection of surrogate measures for evaluating therapeutic interventions.\n"
     ]
    }
   ],
   "source": [
    "# View a top document related to a given topic\n",
    "\n",
    "for topic_idx, topic in enumerate(nmf_H):\n",
    "    print('--------------------')\n",
    "    print(\"Topic %d:\" % (topic_idx))\n",
    "    print('--------------------')\n",
    "    print(\" \".join([vectorizer_feature_names[i]\n",
    "                    for i in topic.argsort()[:-10 - 1:-1]]))\n",
    "    top_doc_indices = np.argsort(nmf_W[:,topic_idx] )[::-1][0:1]\n",
    "    for doc_index in top_doc_indices:\n",
    "        print('--------------------')\n",
    "        print(abstracts_list[doc_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Time to run whole notebook: ')\n",
    "elapsed_time = time.time() - nb_start_time\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
